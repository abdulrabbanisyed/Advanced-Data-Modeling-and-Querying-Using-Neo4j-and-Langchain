{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "GraphDB with Langchain"
      ],
      "metadata": {
        "id": "znG3wReFvNgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRAPH DB Configuration\n",
        "NEO4J_URI=\"neo4j+s://68a573b0.databases.neo4j.io\"\n",
        "NEO4J_USERNAME=\"neo4j\"\n",
        "NEO4J_PASSWORD=\"Hw8UFW3504zgK08kxGsDSmJSMj77zI3Hi0SJgxI6Zlg\"\n"
      ],
      "metadata": {
        "id": "vnigpUq4fBL9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"NEO4J_URI\"] = NEO4J_URI\n",
        "os.environ[\"NEO4J_USERNAME\"] = NEO4J_USERNAME\n",
        "os.environ[\"NEO4J_PASSWORD\"] = NEO4J_PASSWORD"
      ],
      "metadata": {
        "id": "hO5Ij60GfaEe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.graphs import Neo4jGraph\n",
        "graph = Neo4jGraph(\n",
        "    url=os.environ.get(\"NEO4J_URI\"),\n",
        "    username=os.environ.get(\"NEO4J_USERNAME\"),\n",
        "    password=os.environ.get(\"NEO4J_PASSWORD\"),\n",
        ")"
      ],
      "metadata": {
        "id": "xhvCqGZ2fz2-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Njpr1AyejSL",
        "outputId": "13657bfe-97db-49c8-e697-96fbb0a29190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.7/293.7 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --quiet Langchain Langchain-community Langchain-groq neo4j"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfJ54jDzganD",
        "outputId": "2bd0b505-ad63-4358-c2fc-1731758d7b4f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.graphs.neo4j_graph.Neo4jGraph at 0x79fd41a45f00>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groq_api_key = \"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\""
      ],
      "metadata": {
        "id": "xtTYNb2Sgk9l"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"Gemma2-9b-It\")\n",
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTW5C6v8hUi-",
        "outputId": "0722f66a-c8ba-4a2a-8896-bed216792e9d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x79fd0f3d1120>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x79fd0f3d0460>, model_name='Gemma2-9b-It', groq_api_key=SecretStr('**********'))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "text = \"\"\"\n",
        "Pichai began his career as a materials engineer. Following a short stint at the management consulting firm McKinsey & Co., Pichai joined Google in 2004,\n",
        "where he led the product management and innovation efforts for a suite of Google's client software products, including Google Chrome and ChromeOS,\n",
        "as well as being largely responsible for Google Drive. In addition, he went on to oversee the development of other applications such as Gmail and Google Maps. In 2010, Pichai also announced the open-sourcing of the new video codec VP8 by Google and introduced the new video format, WebM.\n",
        "The Chromebook was released in 2012. In 2013, Pichai added Android to the list of Google products that he oversaw.\n",
        "\"\"\"\n",
        "documents = [Document(page_content=text)]\n",
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkBEL5ADiAhM",
        "outputId": "06c62823-262d-45e6-9355-477c7eb1fd74"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"\\nPichai began his career as a materials engineer. Following a short stint at the management consulting firm McKinsey & Co., Pichai joined Google in 2004,\\nwhere he led the product management and innovation efforts for a suite of Google's client software products, including Google Chrome and ChromeOS, \\nas well as being largely responsible for Google Drive. In addition, he went on to oversee the development of other applications such as Gmail and Google Maps. In 2010, Pichai also announced the open-sourcing of the new video codec VP8 by Google and introduced the new video format, WebM. \\nThe Chromebook was released in 2012. In 2013, Pichai added Android to the list of Google products that he oversaw.\\n\")]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet langchain_experimental"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVX1e6TcjvRQ",
        "outputId": "5b0d54ce-3a82-47b5-f2e7-983de582099f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/203.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "llm_transformer = LLMGraphTransformer(llm=llm)"
      ],
      "metadata": {
        "id": "O-CsWB8Dic-R"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_documents = llm_transformer.convert_to_graph_documents(documents)"
      ],
      "metadata": {
        "id": "ohokOWrQj_jG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_documents[0].relationships"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfuosFfHkRXC",
        "outputId": "f0c92fb6-b0df-4a95-e9dc-1f3556dbf878"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Relationship(source=Node(id='Pichai', type='Person'), target=Node(id='Mckinsey & Co.', type='Company'), type='WORKED_AT'),\n",
              " Relationship(source=Node(id='Pichai', type='Person'), target=Node(id='Google', type='Company'), type='WORKED_AT'),\n",
              " Relationship(source=Node(id='Pichai', type='Person'), target=Node(id='Google Chrome', type='Software'), type='LED_DEVELOPMENT'),\n",
              " Relationship(source=Node(id='Pichai', type='Person'), target=Node(id='Chromeos', type='Software'), type='LED_DEVELOPMENT'),\n",
              " Relationship(source=Node(id='Pichai', type='Person'), target=Node(id='Google Drive', type='Software'), type='LED_DEVELOPMENT'),\n",
              " Relationship(source=Node(id='Pichai', type='Person'), target=Node(id='Gmail', type='Software'), type='LED_DEVELOPMENT'),\n",
              " Relationship(source=Node(id='Pichai', type='Person'), target=Node(id='Google Maps', type='Software'), type='LED_DEVELOPMENT'),\n",
              " Relationship(source=Node(id='Google', type='Company'), target=Node(id='Vp8', type='Video codec'), type='DEVELOPED'),\n",
              " Relationship(source=Node(id='Google', type='Company'), target=Node(id='Webm', type='Video format'), type='DEVELOPED'),\n",
              " Relationship(source=Node(id='Google', type='Company'), target=Node(id='Chromebook', type='Hardware'), type='DEVELOPED'),\n",
              " Relationship(source=Node(id='Pichai', type='Person'), target=Node(id='Android', type='Software'), type='OVERSEES_DEVELOPMENT')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Load the dataset of movie\n",
        "\n",
        "movie_query=\"\"\"\n",
        "LOAD CSV WITH HEADERS FROM\n",
        "'https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/movies/movies_small.csv' as row\n",
        "\n",
        "MERGE(m:Movie{id:row.movieId})\n",
        "SET m.released = date(row.released),\n",
        "    m.title = row.title,\n",
        "    m.imdbRating = toFloat(row.imdbRating)\n",
        "FOREACH (director in split(row.director, '|') |\n",
        "    MERGE (p:Person {name:trim(director)})\n",
        "    MERGE (p)-[:DIRECTED]->(m))\n",
        "FOREACH (actor in split(row.actors, '|') |\n",
        "    MERGE (p:Person {name:trim(actor)})\n",
        "    MERGE (p)-[:ACTED_IN]->(m))\n",
        "FOREACH (genre in split(row.genres, '|') |\n",
        "    MERGE (g:Genre {name:trim(genre)})\n",
        "    MERGE (m)-[:IN_GENRE]->(g))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "shauLdXwmPSY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph.query(movie_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5uPkADKspXj",
        "outputId": "c1b9c0ac-8180-4b29-8c76-82bb6df9f4af"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.refresh_schema()\n",
        "print(graph.schema)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P109rAHtcQv",
        "outputId": "50cd18af-c467-4a02-9a30-5fce8657e59e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node properties:\n",
            "Person {name: STRING, born: INTEGER, place: STRING}\n",
            "Movie {id: STRING, released: DATE, title: STRING, imdbRating: FLOAT}\n",
            "Genre {name: STRING}\n",
            "Relationship properties:\n",
            "\n",
            "The relationships:\n",
            "(:Person)-[:Loves]->(:Person)\n",
            "(:Person)-[:DIRECTED]->(:Movie)\n",
            "(:Person)-[:ACTED_IN]->(:Movie)\n",
            "(:Movie)-[:IN_GENRE]->(:Genre)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import GraphCypherQAChain\n",
        "chain = GraphCypherQAChain.from_llm(\n",
        "    llm, graph=graph, verbose=True\n",
        ")\n",
        "chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efFRxlc-srVy",
        "outputId": "ef4571cf-6050-4a97-b4ca-627e00aafc2c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GraphCypherQAChain(verbose=True, graph=<langchain_community.graphs.neo4j_graph.Neo4jGraph object at 0x79fd41a45f00>, cypher_generation_chain=LLMChain(prompt=PromptTemplate(input_variables=['question', 'schema'], template='Task:Generate Cypher statement to query a graph database.\\nInstructions:\\nUse only the provided relationship types and properties in the schema.\\nDo not use any other relationship types or properties that are not provided.\\nSchema:\\n{schema}\\nNote: Do not include any explanations or apologies in your responses.\\nDo not respond to any questions that might ask anything else than for you to construct a Cypher statement.\\nDo not include any text except the generated Cypher statement.\\n\\nThe question is:\\n{question}'), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x79fd0f3d1120>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x79fd0f3d0460>, model_name='Gemma2-9b-It', groq_api_key=SecretStr('**********'))), qa_chain=LLMChain(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant that helps to form nice and human understandable answers.\\nThe information part contains the provided information that you must use to construct an answer.\\nThe provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\\nMake the answer sound as a response to the question. Do not mention that you based the result on the given information.\\nHere is an example:\\n\\nQuestion: Which managers own Neo4j stocks?\\nContext:[manager:CTL LLC, manager:JANE STREET GROUP LLC]\\nHelpful Answer: CTL LLC, JANE STREET GROUP LLC owns Neo4j stocks.\\n\\nFollow this example when generating answers.\\nIf the provided information is empty, say that you don't know the answer.\\nInformation:\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x79fd0f3d1120>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x79fd0f3d0460>, model_name='Gemma2-9b-It', groq_api_key=SecretStr('**********'))), graph_schema='Node properties are the following:\\nPerson {name: STRING, born: INTEGER, place: STRING},Movie {id: STRING, released: DATE, title: STRING, imdbRating: FLOAT},Genre {name: STRING}\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n(:Person)-[:Loves]->(:Person),(:Person)-[:DIRECTED]->(:Movie),(:Person)-[:ACTED_IN]->(:Movie),(:Movie)-[:IN_GENRE]->(:Genre)')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=chain.invoke({\"query\":\"Who was the director of the movie Casino\"})\n",
        "\n",
        "response\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsGRKPq2trJy",
        "outputId": "adaf7714-e740-406d-c883-6cba78668f7c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mMATCH (m:Movie {id: 'Casino'})<-[:DIRECTED]-(p:Person) RETURN p.name \n",
            "\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Who was the director of the movie Casino',\n",
              " 'result': \"I don't know the answer. \\n\"}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1z8tOGOltyEI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}